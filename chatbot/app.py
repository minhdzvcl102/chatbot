import socket
import json
import threading
import time
import logging
import os
import signal
import sys
from datetime import datetime
from typing import Dict, Optional, Any, List
from dotenv import load_dotenv
from openai import OpenAI
from openai.types.chat import ChatCompletionMessageParam

# Add random import back for fallback responses
import random

# Configure logging with UTF-8 encoding
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_service.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

# Set console encoding to UTF-8
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

logger = logging.getLogger(__name__)

class AIService:
    def __init__(self, host='localhost', port=8888):
        self.host = host
        self.port = port
        self.server_socket = None
        self.running = False
        self.clients = {}
        self.conversation_history = {}
        
        # AI service configuration
        self.max_history_length = int(os.getenv('MAX_HISTORY_LENGTH', '20'))
        self.response_delay = float(os.getenv('AI_RESPONSE_DELAY', '0.5'))
        
        # Initialize OpenAI client with DashScope
        self.openai_client = None
        self.setup_openai_client()
        
        logger.info(f"ü§ñ AI Service initialized on {host}:{port}")
    
    def setup_openai_client(self):
        """Setup OpenAI client with Alibaba DashScope"""
        try:
            api_key = os.getenv("ALIBABA_API_KEY")
            base_url = os.getenv("BASE_API_URL")
            
            if not api_key:
                logger.warning("‚ö†Ô∏è ALIBABA_API_KEY not found, using fallback responses")
                return
            
            self.openai_client = OpenAI(
                api_key=api_key,
                base_url=base_url
            )
            
            logger.info("‚úÖ OpenAI client initialized with DashScope")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize OpenAI client: {e}")
            logger.warning("‚ö†Ô∏è Falling back to local responses")
    
    def start_server(self):
        """Start the socket server"""
        try:
            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.server_socket.bind((self.host, self.port))
            self.server_socket.listen(10)
            
            self.running = True
            logger.info(f"üöÄ AI Service server started on {self.host}:{self.port}")
            
            while self.running:
                try:
                    client_socket, address = self.server_socket.accept()
                    logger.info(f"üîó New connection from {address}")
                    
                    # Handle each client in a separate thread
                    client_thread = threading.Thread(
                        target=self.handle_client,
                        args=(client_socket, address),
                        daemon=True
                    )
                    client_thread.start()
                    
                except socket.error as e:
                    if self.running:
                        logger.error(f"‚ùå Socket error: {e}")
                    break
                    
        except Exception as e:
            logger.error(f"‚ùå Failed to start server: {e}")
        finally:
            self.cleanup()
    
    def handle_client(self, client_socket, address):
        """Handle individual client connection"""
        client_id = f"{address[0]}:{address[1]}"
        self.clients[client_id] = {
            'socket': client_socket,
            'address': address,
            'connected_at': datetime.now()
        }
        
        try:
            buffer = ""
            while self.running:
                # Receive data from client
                data = client_socket.recv(4096).decode('utf-8')
                if not data:
                    break
                
                buffer += data
                
                # Process complete messages (newline-delimited JSON)
                while '\n' in buffer:
                    line, buffer = buffer.split('\n', 1)
                    line = line.strip()
                    
                    if line:
                        try:
                            request = json.loads(line)
                            response = self.process_request(request)
                            
                            if response:
                                response_json = json.dumps(response) + '\n'
                                client_socket.send(response_json.encode('utf-8'))
                                
                        except json.JSONDecodeError as e:
                            logger.error(f"‚ùå JSON decode error from {client_id}: {e}")
                            error_response = {
                                'status': 'error',
                                'error': 'Invalid JSON format',
                                'timestamp': datetime.now().isoformat()
                            }
                            client_socket.send((json.dumps(error_response) + '\n').encode('utf-8'))
                        
                        except Exception as e:
                            logger.error(f"‚ùå Error processing request from {client_id}: {e}")
                            error_response = {
                                'status': 'error',
                                'error': str(e),
                                'timestamp': datetime.now().isoformat()
                            }
                            client_socket.send((json.dumps(error_response) + '\n').encode('utf-8'))
                
        except ConnectionResetError:
            logger.info(f"üîå Client {client_id} disconnected")
        except Exception as e:
            logger.error(f"‚ùå Error handling client {client_id}: {e}")
        finally:
            try:
                client_socket.close()
            except:
                pass
            
            if client_id in self.clients:
                del self.clients[client_id]
            
            logger.info(f"üëã Client {client_id} connection closed")
    
    def process_request(self, request: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Process AI request and generate response"""
        try:
            request_type = request.get('type', 'chat')
            conversation_id = request.get('conversationId')
            message = request.get('message', '')
            username = request.get('username', 'User')
            
            logger.info(f"üì• Processing {request_type} request for conversation {conversation_id}")
            
            if request_type == 'chat':
                return self.handle_chat_request(conversation_id, message, username)
            elif request_type == 'system':
                return self.handle_system_request(request)
            else:
                return {
                    'status': 'error',
                    'error': f'Unknown request type: {request_type}',
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error processing request: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def handle_chat_request(self, conversation_id: str, message: str, username: str) -> Dict[str, Any]:
        """Handle chat request and generate AI response"""
        try:
            # Initialize conversation history if not exists
            if conversation_id not in self.conversation_history:
                self.conversation_history[conversation_id] = []
            
            # Add user message to history
            self.conversation_history[conversation_id].append({
                'role': 'user',
                'content': message,
                'username': username,
                'timestamp': datetime.now().isoformat()
            })
            
            # Trim history if too long
            if len(self.conversation_history[conversation_id]) > self.max_history_length:
                self.conversation_history[conversation_id] = self.conversation_history[conversation_id][-self.max_history_length:]
            
            # Simulate AI processing delay
            time.sleep(self.response_delay)
            
            # Generate AI response based on the message
            ai_response = self.generate_ai_response(message, conversation_id, username)
            
            # Add AI response to history
            self.conversation_history[conversation_id].append({
                'role': 'assistant',
                'content': ai_response,
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info(f"ü§ñ Generated AI response for conversation {conversation_id}")
            
            return {
                'status': 'success',
                'content': ai_response,
                'conversation_id': conversation_id,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error handling chat request: {e}")
            return {
                'status': 'error',
                'error': f'Failed to process chat request: {str(e)}',
                'timestamp': datetime.now().isoformat()
            }
    
    def generate_ai_response(self, message: str, conversation_id: str, username: str) -> str:
        """Generate AI response using OpenAI/DashScope or fallback to local responses"""
        
        # Try OpenAI/DashScope first
        if self.openai_client:
            try:
                return self.generate_openai_response(message, conversation_id, username)
            except Exception as e:
                logger.error(f"‚ùå OpenAI API error: {e}")
                logger.info("üîÑ Falling back to local response generation")
        
        # Fallback to local response generation
        return self.generate_local_response(message, conversation_id, username)
    
    def generate_openai_response(self, message: str, conversation_id: str, username: str) -> str:
        """Generate response using OpenAI/DashScope API"""
        try:
            logger.info(f"ü§ñ Generating OpenAI response for user: {username}")
            
            # Prepare conversation history for API
            messages: List[ChatCompletionMessageParam] = []
            
            # Add conversation context
            if conversation_id in self.conversation_history:
                history = self.conversation_history[conversation_id]
                # Take last few messages for context (limit to save tokens)
                recent_history = history[-10:] if len(history) > 10 else history
                
                for msg in recent_history:
                    if msg['role'] in ['user', 'assistant']:
                        content = msg['content']
                        if msg['role'] == 'user' and 'username' in msg:
                            content = f"{msg['username']}: {content}"
                        
                        messages.append({
                            "role": msg['role'],
                            "content": content
                        })
            
            # Add current message
            messages.append({
                "role": "user", 
                "content": f"{username}: {message}"
            })
            
            # Add system message for context
            system_message = {
                "role": "system",
                "content": f"""B·∫°n l√† m·ªôt AI assistant th√¥ng minh v√† h·ªØu √≠ch. 
                H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch t·ª± nhi√™n v√† th√¢n thi·ªán.
                Ng∆∞·ªùi d√πng hi·ªán t·∫°i l√† {username}.
                H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† ph√π h·ª£p v·ªõi ng·ªØ c·∫£nh cu·ªôc h·ªôi tho·∫°i."""
            }
            messages.insert(0, system_message)
            
            # Call OpenAI API
            response = self.openai_client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "qwen-turbo"),
                messages=messages,
                max_tokens=int(os.getenv("MAX_TOKENS", "500")),
                temperature=float(os.getenv("TEMPERATURE", "0.7")),
                stream=False
            )
            
            ai_response = response.choices[0].message.content.strip()
            logger.info(f"‚úÖ OpenAI response generated successfully")
            
            return ai_response
            
        except Exception as e:
            logger.error(f"‚ùå Error calling OpenAI API: {e}")
            raise e
    
    def generate_local_response(self, message: str, conversation_id: str, username: str) -> str:
        """Generate fallback response locally"""
        message_lower = message.lower().strip()
        
        # Greeting responses
        greetings = ['hello', 'hi', 'hey', 'xin ch√†o', 'ch√†o', 'good morning', 'good afternoon', 'good evening']
        if any(greeting in message_lower for greeting in greetings):
            responses = [
                f"Xin ch√†o {username}! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n h√¥m nay?",
                f"Ch√†o {username}! B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?",
                f"Hello {username}! R·∫•t vui ƒë∆∞·ª£c g·∫∑p b·∫°n. T√¥i c√≥ th·ªÉ h·ªó tr·ª£ g√¨?",
                f"Ch√†o b·∫°n {username}! T√¥i ·ªü ƒë√¢y ƒë·ªÉ gi√∫p ƒë·ª°. B·∫°n mu·ªën h·ªèi g√¨?"
            ]
            return random.choice(responses)
        
        # Question responses  
        if any(starter in message_lower for starter in ['what', 'how', 'why', 'g√¨', 'sao', 'th·∫ø n√†o', 't·∫°i sao', 'l√†m sao']):
            responses = [
                f"ƒê√¢y l√† m·ªôt c√¢u h·ªèi hay! ƒê·ªÉ t√¥i suy nghƒ© v·ªÅ ƒëi·ªÅu ƒë√≥ cho b·∫°n.",
                f"C√¢u h·ªèi th√∫ v·ªã! D·ª±a tr√™n hi·ªÉu bi·∫øt c·ªßa t√¥i, ƒë√¢y l√† quan ƒëi·ªÉm c·ªßa t√¥i:",
                f"T√¥i r·∫•t vui khi gi√∫p b·∫°n hi·ªÉu r√µ h∆°n v·ªÅ v·∫•n ƒë·ªÅ n√†y.",
                f"ƒê√≥ l√† ƒëi·ªÅu ƒë√°ng kh√°m ph√°. ƒê√¢y l√† nh·ªØng g√¨ t√¥i c√≥ th·ªÉ chia s·∫ª:"
            ]
            base_response = random.choice(responses)
            
            # Add context-specific information
            if any(word in message_lower for word in ['th·ªùi ti·∫øt', 'weather']):
                return f"{base_response} T√¥i kh√¥ng c√≥ quy·ªÅn truy c·∫≠p d·ªØ li·ªáu th·ªùi ti·∫øt th·ªùi gian th·ª±c, nh∆∞ng t√¥i khuy√™n b·∫°n n√™n ki·ªÉm tra d·ªãch v·ª• th·ªùi ti·∫øt ƒë√°ng tin c·∫≠y."
            elif any(word in message_lower for word in ['th·ªùi gian', 'time', 'gi·ªù']):
                current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                return f"{base_response} Th·ªùi gian server hi·ªán t·∫°i l√† {current_time}."
            elif any(word in message_lower for word in ['gi√∫p', 'help', 'h·ªó tr·ª£']):
                return f"{base_response} T√¥i l√† tr·ª£ l√Ω AI ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p v·ªõi c√°c nhi·ªám v·ª• kh√°c nhau v√† tr·∫£ l·ªùi c√¢u h·ªèi. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨!"
            else:
                return f"{base_response} T√¥i s·∫Ω c·ªë g·∫Øng cung c·∫•p th√¥ng tin h·ªØu √≠ch v·ªÅ c√¢u h·ªèi c·ªßa b·∫°n."
        
        # Programming/technical questions
        programming_keywords = ['code', 'programming', 'function', 'algorithm', 'debug', 'error', 'javascript', 'python', 'nodejs', 'l·∫≠p tr√¨nh', 'code', 'thu·∫≠t to√°n']
        if any(keyword in message_lower for keyword in programming_keywords):
            responses = [
                "T√¥i r·∫•t vui khi gi√∫p b·∫°n v·ªõi c√¢u h·ªèi l·∫≠p tr√¨nh! B·∫°n c√≥ th·ªÉ cung c·∫•p chi ti·∫øt c·ª• th·ªÉ h∆°n kh√¥ng?",
                "C√¢u h·ªèi l·∫≠p tr√¨nh l√† chuy√™n m√¥n c·ªßa t√¥i! B·∫°n mu·ªën ƒë∆∞·ª£c h·ªó tr·ª£ kh√≠a c·∫°nh n√†o c·ª• th·ªÉ?",
                "ƒê·ªÉ t√¥i gi√∫p b·∫°n v·ªõi v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t n√†y. B·∫°n c√≥ th·ªÉ chia s·∫ª th√™m ng·ªØ c·∫£nh kh√¥ng?",
                "T√¥i c√≥ th·ªÉ h·ªó tr·ª£ v·ªõi c√°c v·∫•n ƒë·ªÅ coding. B·∫°n ƒëang l√†m vi·ªác v·ªõi ng√¥n ng·ªØ l·∫≠p tr√¨nh ho·∫∑c framework n√†o?"
            ]
            return random.choice(responses)
        
        # Farewell responses
        farewells = ['bye', 'goodbye', 'see you', 'farewell', 'take care', 't·∫°m bi·ªát', 'ch√†o', 'h·∫πn g·∫∑p l·∫°i']
        if any(farewell in message_lower for farewell in farewells):
            responses = [
                f"T·∫°m bi·ªát {username}! R·∫•t vui ƒë∆∞·ª£c tr√≤ chuy·ªán v·ªõi b·∫°n.",
                f"ChƒÉm s√≥c b·∫£n th√¢n nh√© {username}! B·∫°n c√≥ th·ªÉ quay l·∫°i b·∫•t c·ª© l√∫c n√†o.",
                f"H·∫πn g·∫∑p l·∫°i {username}! Ch√∫c b·∫°n m·ªôt ng√†y tuy·ªát v·ªùi!",
                f"T·∫°m bi·ªát {username}! C·∫£m ∆°n b·∫°n ƒë√£ tr√≤ chuy·ªán."
            ]
            return random.choice(responses)
        
        # Thank you responses
        thanks = ['thank', 'thanks', 'appreciate', 'c·∫£m ∆°n', 'c√°m ∆°n', 'thanks']
        if any(thank in message_lower for thank in thanks):
            responses = [
                f"B·∫°n r·∫•t ƒë∆∞·ª£c ch√†o ƒë√≥n {username}! Vui khi ƒë∆∞·ª£c gi√∫p ƒë·ª°.",
                f"Kh√¥ng c√≥ g√¨ {username}! ƒê√≥ l√† ƒëi·ªÅu t√¥i ·ªü ƒë√¢y ƒë·ªÉ l√†m.",
                f"Vui khi c√≥ th·ªÉ gi√∫p ƒë∆∞·ª£c {username}! H√£y h·ªèi t√¥i n·∫øu b·∫°n c·∫ßn g√¨ kh√°c.",
                f"Kh√¥ng c√≥ chi {username}! T√¥i r·∫•t vui khi ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n."
            ]
            return random.choice(responses)
        
        # Default responses for general messages
        default_responses = [
            f"T√¥i hi·ªÉu nh·ªØng g√¨ b·∫°n ƒëang n√≥i, {username}. B·∫°n c√≥ th·ªÉ n√≥i th√™m v·ªÅ ƒëi·ªÅu ƒë√≥ kh√¥ng?",
            f"ƒêi·ªÅu ƒë√≥ th√∫ v·ªã, {username}. B·∫°n c√≥ mu·ªën th·∫£o lu·∫≠n th√™m v·ªÅ ch·ªß ƒë·ªÅ n√†y kh√¥ng?",
            f"T√¥i nghe b·∫°n, {username}. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ƒëi·ªÅu g√¨ v·ªõi v·∫•n ƒë·ªÅ n√†y?",
            f"C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª, {username}. B·∫°n mu·ªën bi·∫øt th√™m v·ªÅ ƒëi·ªÅu g√¨?",
            f"T√¥i hi·ªÉu, {username}. C√≥ ƒëi·ªÅu g√¨ c·ª• th·ªÉ b·∫°n mu·ªën ƒë∆∞·ª£c h·ªó tr·ª£ kh√¥ng?",
            f"ƒêi·ªÅu ƒë√≥ c√≥ l√Ω, {username}. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n h√¥m nay kh√¥ng?"
        ]
        
        return random.choice(default_responses)
    
    def handle_system_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle system requests like health checks, stats, etc."""
        try:
            command = request.get('command', '')
            
            if command == 'health':
                return {
                    'status': 'success',
                    'health': 'healthy',
                    'uptime': time.time(),
                    'active_clients': len(self.clients),
                    'active_conversations': len(self.conversation_history),
                    'timestamp': datetime.now().isoformat()
                }
            
            elif command == 'stats':
                return {
                    'status': 'success',
                    'stats': {
                        'active_clients': len(self.clients),
                        'active_conversations': len(self.conversation_history),
                        'total_messages': sum(len(history) for history in self.conversation_history.values()),
                        'server_start_time': datetime.now().isoformat(),
                        'configuration': {
                            'max_history_length': self.max_history_length,
                            'response_delay': self.response_delay
                        }
                    },
                    'timestamp': datetime.now().isoformat()
                }
            
            elif command == 'clear_history':
                conversation_id = request.get('conversation_id')
                if conversation_id and conversation_id in self.conversation_history:
                    del self.conversation_history[conversation_id]
                    return {
                        'status': 'success',
                        'message': f'History cleared for conversation {conversation_id}',
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    return {
                        'status': 'error',
                        'error': 'Invalid or missing conversation_id',
                        'timestamp': datetime.now().isoformat()
                    }
            
            else:
                return {
                    'status': 'error',
                    'error': f'Unknown system command: {command}',
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error handling system request: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def cleanup(self):
        """Clean up server resources"""
        logger.info("üßπ Cleaning up AI Service...")
        
        self.running = False
        
        # Close all client connections
        for client_id, client_info in self.clients.items():
            try:
                client_info['socket'].close()
            except:
                pass
        
        self.clients.clear()
        
        # Close server socket
        if self.server_socket:
            try:
                self.server_socket.close()
            except:
                pass
        
        logger.info("‚úÖ AI Service cleanup completed")
    
    def signal_handler(self, signum, frame):
        """Handle shutdown signals"""
        logger.info(f"üì° Received signal {signum}, shutting down...")
        self.cleanup()
        sys.exit(0)

def main():
    """Main function to start the AI service"""
    # Load environment variables
    load_dotenv()
    
    # Get configuration from environment variables
    host = os.getenv('AI_SERVICE_HOST', 'localhost')
    port = int(os.getenv('AI_SERVICE_PORT', '8888'))
    
    # Create AI service instance
    ai_service = AIService(host, port)
    
    # Setup signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, ai_service.signal_handler)
    signal.signal(signal.SIGTERM, ai_service.signal_handler)
    
    try:
        # Start the server
        ai_service.start_server()
    except KeyboardInterrupt:
        logger.info("üõë Keyboard interrupt received")
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {e}")
    finally:
        ai_service.cleanup()

if __name__ == "__main__":
    main()